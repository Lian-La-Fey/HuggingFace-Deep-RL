{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# The Exploration/Exploitation trade-off\n",
    "\n",
    "Son olarak, Reinforcement Learning problemlerini çözmek için farklı yöntemlere bakmadan önce, çok önemli bir konuyu daha ele almalıyız: exploration/exploitation trade-off.\n",
    "\n",
    "- Exploration, çevre hakkında daha fazla bilgi bulmak için rastgele eylemler deneyerek çevreyi keşfetmektir.\n",
    "\n",
    "- Exploitation ise ödülü en üst düzeye çıkarmak için bilinen bilgileri kullanmaktır.\n",
    "\n",
    "Unutmayın, RL ajanımızın amacı beklenen kümülatif ödülü maksimize etmektir. Ancak, yaygın bir tuzağa düşebiliriz.\n",
    "\n",
    "Bir örnek verelim:\n",
    "\n",
    "![image1](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/exp_1.jpg)\n",
    "\n",
    "Bu oyunda, faremiz sonsuz miktarda küçük peynire sahip olabilir (her biri +1). Ancak labirentin tepesinde devasa miktarda peynir vardır (+1000).\n",
    "\n",
    "Ancak, sadece exploitation (sömürmeye) odaklanırsak, ajanımız asla devasa peynir toplamına ulaşamayacaktır. Bunun yerine, sadece en yakın ödül kaynağını kullanacaktır, bu kaynak küçük olsa bile.\n",
    "\n",
    "Ancak ajanımız biraz keşif yaparsa, büyük ödülü (büyük peynir yığınını) keşfedebilir.\n",
    "\n",
    "Buna keşif/sömürü trade-off'u diyoruz. Çevreyi ne kadar keşfettiğimizi ve çevre hakkında bildiklerimizden ne kadar faydalandığımızı dengelememiz gerekir.\n",
    "\n",
    "Bu nedenle, bu dengeyi sağlamaya yardımcı olacak bir kural tanımlamalıyız. İleriki ünitelerde bunu ele almanın farklı yollarını göreceğiz.\n",
    "\n",
    "Özetlemek gerekirse:\n",
    "\n",
    "![image2](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/expexpltradeoff.jpg)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
