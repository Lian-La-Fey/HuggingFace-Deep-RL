{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Two main approaches for solving RL problems\n",
    "\n",
    "Başka bir deyişle, beklenen kümülatif ödülünü maksimize eden eylemleri seçebilen bir RL ajanını nasıl oluşturabiliriz?\n",
    "\n",
    "## The Policy π: the agent’s brain\n",
    "\n",
    "Politika π, Ajanımızın beynidir, içinde bulunduğumuz durum göz önüne alındığında hangi eylemi gerçekleştireceğimizi söyleyen işlevdir. Yani ajanın belirli bir zamandaki davranışını tanımlar.\n",
    "\n",
    "![image1](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_1.jpg)\n",
    "\n",
    "Bu Politika **öğrenmek istediğimiz fonksiyondur**, amacımız optimal politika π*'yi bulmaktır, ajan buna göre hareket ettiğinde **beklenen getiriyi maksimize eden** politika. Bu π*'yi eğitim yoluyla buluruz.\n",
    "\n",
    "Temsilcimizi bu optimal politika π*'yi bulması için eğitmek için iki yaklaşım vardır:\n",
    "\n",
    "- Doğrudan, ajana mevcut durum göz önüne alındığında hangi **eylemi gerçekleştireceğini** öğreterek: **Politika Tabanlı Yöntemler**.\n",
    "\n",
    "- Dolaylı olarak, ajana **hangi durumun daha değerli olduğunu öğrenmesini** ve ardından **daha değerli durumlara yol açan** eylemi gerçekleştirmesini öğretmek: Değer Tabanlı Yöntemler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Policy-Based Methods\n",
    "\n",
    "Politika Tabanlı yöntemlerde, **doğrudan bir politika fonksiyonu öğreniriz**.\n",
    "\n",
    "Bu fonksiyon her bir durumdan en iyi karşılık gelen eyleme bir eşleme tanımlayacaktır. Alternatif olarak, **o durumdaki olası eylemler kümesi üzerinde bir olasılık dağılımı** tanımlayabilir.\n",
    "\n",
    "![image2](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_2.jpg)\n",
    "\n",
    "İki tür politikamız var:\n",
    "\n",
    "- Deterministik: belirli bir durumdaki bir politika **her zaman aynı eylemi döndürecektir**.\n",
    "\n",
    "![image3](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_3.jpg)\n",
    "\n",
    "![image4](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_4.jpg)\n",
    "\n",
    "Stokastik: **eylemler üzerinde bir olasılık dağılımı** verir.\n",
    "\n",
    "![image5](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy_5.jpg)\n",
    "\n",
    "![image6](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/policy-based.png)\n",
    "\n",
    "Özetlemek gerekirse:\n",
    "\n",
    "![image7](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/pbm_1.jpg)\n",
    "\n",
    "![image8](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/pbm_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Value-based methods\n",
    "\n",
    "Değer temelli yöntemlerde, bir politika fonksiyonu öğrenmek yerine, bir durumu **o durumda olmanın** beklenen değeriyle eşleyen **bir değer fonksiyonu** öğreniriz.\n",
    "\n",
    "Bir durumun değeri, ajanın o durumda başlaması ve ardından politikamıza göre hareket etmesi durumunda elde edebileceği **beklenen indirimli getiridir**.\n",
    "\n",
    "\"Politikamıza göre hareket etmek\" sadece politikamızın \"**en yüksek değere sahip duruma gitmek**\" olduğu anlamına gelir.\n",
    "\n",
    "![image9](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/value_1.jpg)\n",
    "\n",
    "Burada değer fonksiyonumuzun her olası durum için değerler tanımladığını görüyoruz.\n",
    "\n",
    "![image10](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/value_2.jpg)\n",
    "\n",
    "Değer fonksiyonumuz sayesinde, politikamız her adımda değer fonksiyonu tarafından tanımlanan en büyük değere sahip durumu seçecektir: -7, sonra -6, sonra -5 (ve böyle devam eder) hedefe ulaşmak için.\n",
    "\n",
    "![image11](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/vbm_1.jpg)\n",
    "\n",
    "![image12](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/vbm_2.jpg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
