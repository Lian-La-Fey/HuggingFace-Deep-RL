{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Q-Learning\n",
    "\n",
    "![image1](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/thumbnail.jpg)\n",
    "\n",
    "Bu dersin ilk ünitesinde, Reinforcement Learning (RL), RL süreci ve bir RL problemini çözmek için farklı yöntemler hakkında bilgi edindik. Ayrıca ilk ajanlarımızı eğittik ve onları Hugging Face Hub'a yükledik.\n",
    "\n",
    "Bu ünitede, Reinforcement Learning yöntemlerinden biri olan değer tabanlı yöntemlere daha derinlemesine dalacağız ve ilk RL algoritmamızı inceleyeceğiz: **Q-Learning**.\n",
    "\n",
    "Ayrıca **ilk RL ajanımızı sıfırdan, bir Q-Learning ajanı olarak uygulayacağız** ve iki ortamda eğiteceğiz:\n",
    "\n",
    "- Frozen-Lake-v1 (kaygan olmayan versiyon): ajanımızın başlangıç durumundan (S) hedef durumuna (G) sadece donmuş karolar (F) üzerinde yürüyerek ve deliklerden (H) kaçınarak gitmesi gerekecek.\n",
    "\n",
    "- Otonom bir taksi: Temsilcimizin yolcularını A noktasından B noktasına taşımak için bir şehirde gezinmeyi öğrenmesi gerekecektir.\n",
    "\n",
    "![image2](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/envs.gif)\n",
    "\n",
    "Somut olarak, şunları yapacağız:\n",
    "\n",
    "- Değer tabanlı yöntemler hakkında bilgi edinin.\n",
    "- Monte Carlo ve Zamansal Fark Öğrenimi arasındaki farklar hakkında bilgi edineceğiz.\n",
    "- İlk RL algoritmamızı inceleyip uygulayacağız: Q-Learning.\n",
    "\n",
    "Atari oyunlarını oynayan ve bazılarında insan seviyesini geçen (breakout, space invaders, vb.) ilk Derin RL algoritması olan Derin Q-Öğrenme üzerinde çalışabilmek istiyorsanız bu ünite çok önemlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# What is RL? A short recap\n",
    "\n",
    "RL'de, **akıllı kararlar verebilen** bir ajan inşa ederiz. Örneğin, **video oyunu oynamayı öğrenen** bir ajan ya da **hangi hisse senetlerini alıp ne zaman satacağına** karar vererek **kazancını maksimize etmeyi** öğrenen bir ticaret ajanı.\n",
    "\n",
    "![RL process](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/rl-process.jpg)\n",
    "\n",
    "Akıllı kararlar vermek için, ajanımız **deneme ve yanılma** yoluyla çevreyle etkileşime girerek ve **benzersiz geri bildirim** olarak ödüller (olumlu veya olumsuz) alarak çevreden öğrenecektir.\n",
    "\n",
    "Amacı **beklenen kümülatif ödülünü** maksimize etmektir (ödül hipotezi nedeniyle).\n",
    "\n",
    "**Ajanın karar verme sürecine politika π denir:** bir durum verildiğinde, bir politika bir eylem veya eylemler üzerinde bir olasılık dağılımı çıkaracaktır. Yani, çevrenin bir gözlemi verildiğinde, bir politika ajanın yapması gereken bir eylem (veya her eylem için birden fazla olasılık) sağlayacaktır.\n",
    "\n",
    "![Policy](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/policy.jpg)\n",
    "\n",
    "**Amacımız en uygun π\\*** politikasını, yani en iyi beklenen kümülatif ödülü sağlayan politikayı bulmaktır.\n",
    "\n",
    "Ve bu optimal politikayı bulmak için (dolayısıyla RL problemini çözmek için), **iki ana RL yöntemi** vardır:\n",
    "\n",
    "- *Policy-based methods*: Bir durum karşısında hangi eylemi gerçekleştireceğini öğrenmek için **politikayı doğrudan eğitin**.\n",
    "- *Value-based methods*: **Hangi durumun daha değerli olduğunu** öğrenmek için bir **değer fonksiyonunu eğitin** ve bu değer fonksiyonunu **bu duruma yol açan eylemi gerçekleştirmek için** kullanın.\n",
    "\n",
    "![Two RL approaches](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/two-approaches.jpg)\n",
    "\n",
    "Ve bu ünitede, **değer temelli yöntemleri daha derinlemesine inceleyeceğiz.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
